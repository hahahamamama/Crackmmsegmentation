{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hahahamamama/Crackmmsegmentation/blob/main/%E6%AC%A2%E8%BF%8E%E4%BD%BF%E7%94%A8_Colaboratory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**深度学习之裂缝训练**"
      ],
      "metadata": {
        "id": "J1M_pnPZsThM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***查看并选择Python版本***"
      ],
      "metadata": {
        "id": "lALEqHGssjUL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gE-Ez1qtyIA",
        "outputId": "d0ce4d7a-b502-4e5e-af2e-951c5210fc4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 choices for the alternative python3 (providing /usr/bin/python3).\n",
            "\n",
            "  Selection    Path                Priority   Status\n",
            "------------------------------------------------------------\n",
            "* 0            /usr/bin/python3.7   2         auto mode\n",
            "  1            /usr/bin/python3.6   1         manual mode\n",
            "  2            /usr/bin/python3.7   2         manual mode\n",
            "\n",
            "Press <enter> to keep the current choice[*], or type selection number: 0\n"
          ]
        }
      ],
      "source": [
        "!sudo update-alternatives --config python3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/Swin-Transformer-Semantic-Segmentation/mmseg/datasets/crack.py /content/drive/MyDrive/mmsegmentation/mmseg/datasets"
      ],
      "metadata": {
        "id": "4fxQV_fT3cmV"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir checkpoints\n",
        "!mkdir data"
      ],
      "metadata": {
        "id": "8qLDyzH23vvR"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/Swin-Transformer-Semantic-Segmentation/checkpoints/upernet_swin_tiny_patch4_window7_512x512_160k_ade20k_pretrain_224x224_1K_20210531_112542-e380ad3e.pth /content/drive/MyDrive/mmsegmentation/checkpoints"
      ],
      "metadata": {
        "id": "LpXE0NIV3vh5"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/Swin-Transformer-Semantic-Segmentation/configs/_base_/datasets/crack.py /content/drive/MyDrive/mmsegmentation/configs/_base_/datasets"
      ],
      "metadata": {
        "id": "ppyMtHYo8h2x"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/Swin-Transformer-Semantic-Segmentation/configs/swin/upernet_swin_tiny_patch4_window7_256*256_40k_ade20k_pretrain_224*224_1Kcrack.py /content/drive/MyDrive/mmsegmentation/configs/swin"
      ],
      "metadata": {
        "id": "qz2WC_4N8hqZ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/Swin-Transformer-Semantic-Segmentation/data/images /content/drive/MyDrive/mmsegmentation/data"
      ],
      "metadata": {
        "id": "6XM2RjMj7z8B"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/Swin-Transformer-Semantic-Segmentation/data/labels /content/drive/MyDrive/mmsegmentation/data\n"
      ],
      "metadata": {
        "id": "O0l1HZUo8n9s"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/Swin-Transformer-Semantic-Segmentation/data/splits /content/drive/MyDrive/mmsegmentation/data"
      ],
      "metadata": {
        "id": "9I8ig26w9mYY"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**环境配置重装torch for mmsegmentation**"
      ],
      "metadata": {
        "id": "CTRbrvJAsEOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kA1bRpynnOIb",
        "outputId": "530b3281-7127-4e79-babf-c6e2af79ca91"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTRKjHKwnu06",
        "outputId": "f0d3f787-35ec-4010-cf61-13a0dc58be8b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon May 16 07:33:30 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   70C    P8    34W / 149W |      3MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo lsb_release -a # 查看系统版本\n",
        "!nvcc -V #或者!nvidia-smi # 查看cuda版本\n",
        "!gcc --version # 查看GCC版本"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8nSLRM6oQbY",
        "outputId": "72d21c49-663c-4789-9f9c-7be9cae4e883"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No LSB modules are available.\n",
            "Distributor ID:\tUbuntu\n",
            "Description:\tUbuntu 18.04.5 LTS\n",
            "Release:\t18.04\n",
            "Codename:\tbionic\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n",
            "gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Copyright (C) 2017 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xj4pBJlokNp",
        "outputId": "a42675a3-111f-46cd-b488-a717bccc87ba"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.8.1+cu111 True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#卸载原有的pytorch\n",
        "!pip uninstall torch torchvision -y\n",
        "#线上安装新的pytorch\n",
        "!pip install -U torch==1.8.1+cu111 torchvision==0.9.1+cu111 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "VCBiKL0YorOa",
        "outputId": "42648a9c-5c2c-42db-a1ca-30c29c899d78"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 1.8.1+cu111\n",
            "Uninstalling torch-1.8.1+cu111:\n",
            "  Successfully uninstalled torch-1.8.1+cu111\n",
            "Found existing installation: torchvision 0.9.1+cu111\n",
            "Uninstalling torchvision-0.9.1+cu111:\n",
            "  Successfully uninstalled torchvision-0.9.1+cu111\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.8.1+cu111\n",
            "tcmalloc: large alloc 1982177280 bytes == 0x345e000 @  0x7f7f4eb461e7 0x4a3940 0x5b438c 0x5ea94f 0x5939cb 0x594cd3 0x5d0ecb 0x59aeca 0x515655 0x593dd7 0x511e2c 0x593dd7 0x511e2c 0x549e0e 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549576 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549576 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549e0e 0x4bca8a 0x59c019\n",
            "tcmalloc: large alloc 1982177280 bytes == 0x796b8000 @  0x7f7f4eb461e7 0x4a3940 0x5b438c 0x64cfe7 0x59b076 0x515655 0x593dd7 0x511e2c 0x593dd7 0x511e2c 0x549e0e 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549576 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549576 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549e0e 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549576\n",
            "tcmalloc: large alloc 1982177280 bytes == 0xef912000 @  0x7f7f4eb461e7 0x4a3940 0x59b5e2 0x63a515 0x63bd66 0x63be16 0x59afff 0x515655 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x593dd7 0x5118f8 0x593dd7 0x511e2c 0x593dd7 0x511e2c 0x549e0e 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549576 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549576\n",
            "tcmalloc: large alloc 1982177280 bytes == 0x165b6c000 @  0x7f7f4eb461e7 0x4a3940 0x59b6f0 0x59f499 0x4d3969 0x512147 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549e0e 0x593fce 0x511e2c 0x549e0e 0x593fce 0x511e2c 0x549e0e 0x593fce 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x593dd7 0x5118f8 0x593dd7 0x511e2c 0x593dd7 0x511e2c\n",
            "tcmalloc: large alloc 1982177280 bytes == 0x1dc5c6000 @  0x7f7f4eb461e7 0x4a3940 0x5b438c 0x638cb2 0x59644e 0x5946b8 0x515600 0x549e0e 0x593fce 0x511e2c 0x549e0e 0x593fce 0x511e2c 0x549e0e 0x593fce 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x593dd7 0x5118f8 0x593dd7 0x511e2c 0x593dd7 0x511e2c 0x549e0e 0x4bca8a 0x59c019 0x595ef6 0x5134a6\n",
            "tcmalloc: large alloc 1982177280 bytes == 0x1dc5c6000 @  0x7f7f4eb461e7 0x4a3940 0x5b438c 0x5ea94f 0x5939cb 0x594cd3 0x5d0ecb 0x59aeca 0x515655 0x593dd7 0x511e2c 0x593dd7 0x511e2c 0x549e0e 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549576 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549576 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549e0e 0x4bca8a 0x59c019\n",
            "tcmalloc: large alloc 2477727744 bytes == 0x345e000 @  0x7f7f4eb47615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x511e2c 0x549e0e 0x593fce\n",
            "  Using cached https://download.pytorch.org/whl/cu111/torch-1.8.1%2Bcu111-cp37-cp37m-linux_x86_64.whl (1982.2 MB)\n",
            "Collecting torchvision==0.9.1+cu111\n",
            "  Using cached https://download.pytorch.org/whl/cu111/torchvision-0.9.1%2Bcu111-cp37-cp37m-linux_x86_64.whl (17.6 MB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1+cu111) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1+cu111) (4.2.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.1+cu111) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.8.1+cu111 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.8.1+cu111 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.8.1+cu111 torchvision-0.9.1+cu111\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchvision"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "path=\"/content/drive/MyDrive/mmsegmentation\"\n",
        "os.chdir(path)\n",
        "os.listdir(path)"
      ],
      "metadata": {
        "id": "q_kv9Ave4GLN",
        "outputId": "124725f7-60a2-444d-9b1b-95d37084539e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.git',\n",
              " '.circleci',\n",
              " '.dev',\n",
              " '.github',\n",
              " '.gitignore',\n",
              " '.owners.yml',\n",
              " '.pre-commit-config.yaml',\n",
              " '.readthedocs.yml',\n",
              " 'CITATION.cff',\n",
              " 'LICENSE',\n",
              " 'MANIFEST.in',\n",
              " 'README.md',\n",
              " 'README_zh-CN.md',\n",
              " 'configs',\n",
              " 'demo',\n",
              " 'docker',\n",
              " 'docs',\n",
              " 'mmseg',\n",
              " 'model-index.yml',\n",
              " 'pytest.ini',\n",
              " 'requirements.txt',\n",
              " 'requirements',\n",
              " 'resources',\n",
              " 'setup.cfg',\n",
              " 'setup.py',\n",
              " 'tests',\n",
              " 'tools',\n",
              " 'mmsegmentation.egg-info']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "path=\"/content/drive/MyDrive\"\n",
        "os.chdir(path)\n",
        "os.listdir(path)"
      ],
      "metadata": {
        "id": "Jxdf2jihx70o",
        "outputId": "3f38c45d-18a2-4fea-9467-075edb9db10b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Google 地球',\n",
              " 'Colab Notebooks',\n",
              " 'PSPNet',\n",
              " 'swintransformers',\n",
              " '.ipynb_checkpoints',\n",
              " 'pytorch',\n",
              " 'Swin-Transformer-Semantic-Segmentation']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "4pjGVQMmxIJe",
        "outputId": "200922df-e1c4-44c5-b5e5-5331a571ae6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/mmsegmentation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/open-mmlab/mmsegmentation.git\n",
        "%cd mmsegmentation"
      ],
      "metadata": {
        "id": "mHsw8NmbyQWk",
        "outputId": "d15ce8b3-8137-407f-d4d7-ceaf10783626",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mmsegmentation'...\n",
            "remote: Enumerating objects: 7001, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 7001 (delta 2), reused 12 (delta 2), pack-reused 6988\u001b[K\n",
            "Receiving objects: 100% (7001/7001), 13.03 MiB | 9.17 MiB/s, done.\n",
            "Resolving deltas: 100% (5184/5184), done.\n",
            "Checking out files: 100% (1211/1211), done.\n",
            "/content/drive/MyDrive/mmsegmentation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mmcv-full\n",
        "!pip install -e .\n",
        "# install Pillow 7.0.0 back in order to avoid bug in colab\n",
        "!pip install Pillow==7.0.0\n",
        "#静候安装完成，预计10min"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yj1122UkpDC2",
        "outputId": "29525501-0c6b-452b-bd46-95e2a9e9202c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mmcv-full in /usr/local/lib/python3.7/dist-packages (1.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (21.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (7.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (1.21.6)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (0.32.0)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (2.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (3.13)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->mmcv-full) (3.0.8)\n",
            "Obtaining file:///content/drive/MyDrive/mmsegmentation\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mmsegmentation==0.24.1) (3.2.2)\n",
            "Requirement already satisfied: mmcls>=0.20.1 in /usr/local/lib/python3.7/dist-packages (from mmsegmentation==0.24.1) (0.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmsegmentation==0.24.1) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mmsegmentation==0.24.1) (21.3)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.7/dist-packages (from mmsegmentation==0.24.1) (3.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmsegmentation==0.24.1) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmsegmentation==0.24.1) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmsegmentation==0.24.1) (3.0.8)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmsegmentation==0.24.1) (1.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mmsegmentation==0.24.1) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->mmsegmentation==0.24.1) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from prettytable->mmsegmentation==0.24.1) (4.11.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prettytable->mmsegmentation==0.24.1) (0.2.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->prettytable->mmsegmentation==0.24.1) (3.8.0)\n",
            "Installing collected packages: mmsegmentation\n",
            "  Attempting uninstall: mmsegmentation\n",
            "    Found existing installation: mmsegmentation 0.11.0\n",
            "    Can't uninstall 'mmsegmentation'. No files were found to uninstall.\n",
            "  Running setup.py develop for mmsegmentation\n",
            "Successfully installed mmsegmentation-0.24.1\n",
            "Requirement already satisfied: Pillow==7.0.0 in /usr/local/lib/python3.7/dist-packages (7.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        " \n",
        "# Check MMSegmentation installation\n",
        "import mmseg\n",
        "print(mmseg.__version__)\n",
        " \n",
        "# Check mmcv installation\n",
        "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
        "print(get_compiling_cuda_version())\n",
        "print(get_compiler_version())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNg2_JvqpS8b",
        "outputId": "2dcf6301-a628-4fca-9231-9615d57ef486"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.8.1+cu111 True\n",
            "0.24.1\n",
            "11.1\n",
            "GCC 7.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "path=\"/content/drive/MyDrive/Swin-Transformer-Semantic-Segmentation\"\n",
        "os.chdir(path)\n",
        "os.listdir(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9Gir4bNoyYG",
        "outputId": "95a503d5-67db-4c01-fcd8-2be700d91f98"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['docker',\n",
              " 'demo',\n",
              " '.readthedocs.yml',\n",
              " '.pre-commit-config.yaml',\n",
              " 'configs',\n",
              " 'README.md',\n",
              " '.github',\n",
              " '.gitignore',\n",
              " '.dev',\n",
              " 'LICENSE',\n",
              " 'requirements',\n",
              " 'docs',\n",
              " 'requirements.txt',\n",
              " 'resources',\n",
              " 'tests',\n",
              " 'tools',\n",
              " 'mmcv_custom',\n",
              " '.git',\n",
              " 'mmseg',\n",
              " 'setup.py',\n",
              " 'pytest.ini',\n",
              " 'setup.cfg',\n",
              " 'mmsegmentation.egg-info',\n",
              " 'checkpoints',\n",
              " 'data',\n",
              " 'example.py']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#命令式训练"
      ],
      "metadata": {
        "id": "W_3BK0KTwR2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python tools/train.py configs/swin/upernet_swin_tiny_patch4_window7_256*256_40k_ade20k_pretrain_224*224_1Kcrack.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnyuR1-DpS5w",
        "outputId": "a6e2f4d1-38f2-49bc-f136-831c74ca0221"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-05-16 08:42:13,053 - mmseg - INFO - Multi-processing start method is `None`\n",
            "2022-05-16 08:42:13,054 - mmseg - INFO - OpenCV num_threads is `<built-in function getNumThreads>\n",
            "2022-05-16 08:42:13,113 - mmseg - INFO - Environment info:\n",
            "------------------------------------------------------------\n",
            "sys.platform: linux\n",
            "Python: 3.7.13 (default, Apr 24 2022, 01:04:09) [GCC 7.5.0]\n",
            "CUDA available: True\n",
            "GPU 0: Tesla K80\n",
            "CUDA_HOME: /usr/local/cuda\n",
            "NVCC: Cuda compilation tools, release 11.1, V11.1.105\n",
            "GCC: x86_64-linux-gnu-gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "PyTorch: 1.8.1+cu111\n",
            "PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 7.3\n",
            "  - C++ Version: 201402\n",
            "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v1.7.0 (Git Hash 7aed236906b1f7a05c0917e5257a1af05e9ff683)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86\n",
            "  - CuDNN 8.0.5\n",
            "  - Magma 2.5.2\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.8.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n",
            "\n",
            "TorchVision: 0.9.1+cu111\n",
            "OpenCV: 4.1.2\n",
            "MMCV: 1.5.0\n",
            "MMCV Compiler: GCC 7.5\n",
            "MMCV CUDA Compiler: 11.1\n",
            "MMSegmentation: 0.24.1+214a0d3\n",
            "------------------------------------------------------------\n",
            "\n",
            "2022-05-16 08:42:13,114 - mmseg - INFO - Distributed training: False\n",
            "2022-05-16 08:42:14,092 - mmseg - INFO - Config:\n",
            "norm_cfg = dict(type='BN', requires_grad=True)\n",
            "backbone_norm_cfg = dict(type='LN', requires_grad=True)\n",
            "model = dict(\n",
            "    type='EncoderDecoder',\n",
            "    pretrained=None,\n",
            "    backbone=dict(\n",
            "        type='SwinTransformer',\n",
            "        pretrain_img_size=224,\n",
            "        embed_dims=96,\n",
            "        patch_size=4,\n",
            "        window_size=7,\n",
            "        mlp_ratio=4,\n",
            "        depths=[2, 2, 6, 2],\n",
            "        num_heads=[3, 6, 12, 24],\n",
            "        strides=(4, 2, 2, 2),\n",
            "        out_indices=(0, 1, 2, 3),\n",
            "        qkv_bias=True,\n",
            "        qk_scale=None,\n",
            "        patch_norm=True,\n",
            "        drop_rate=0.0,\n",
            "        attn_drop_rate=0.0,\n",
            "        drop_path_rate=0.3,\n",
            "        use_abs_pos_embed=False,\n",
            "        act_cfg=dict(type='GELU'),\n",
            "        norm_cfg=dict(type='LN', requires_grad=True),\n",
            "        init_cfg=dict(\n",
            "            type='Pretrained',\n",
            "            checkpoint=\n",
            "            '/content/drive/MyDrive/mmsegmentation/checkpoints/upernet_swin_tiny_patch4_window7_512x512_160k_ade20k_pretrain_224x224_1K_20210531_112542-e380ad3e.pth'\n",
            "        )),\n",
            "    decode_head=dict(\n",
            "        type='UPerHead',\n",
            "        in_channels=[96, 192, 384, 768],\n",
            "        in_index=[0, 1, 2, 3],\n",
            "        pool_scales=(1, 2, 3, 6),\n",
            "        channels=512,\n",
            "        dropout_ratio=0.1,\n",
            "        num_classes=150,\n",
            "        norm_cfg=dict(type='SyncBN', requires_grad=True),\n",
            "        align_corners=False,\n",
            "        loss_decode=dict(\n",
            "            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),\n",
            "    auxiliary_head=dict(\n",
            "        type='FCNHead',\n",
            "        in_channels=384,\n",
            "        in_index=2,\n",
            "        channels=256,\n",
            "        num_convs=1,\n",
            "        concat_input=False,\n",
            "        dropout_ratio=0.1,\n",
            "        num_classes=150,\n",
            "        norm_cfg=dict(type='SyncBN', requires_grad=True),\n",
            "        align_corners=False,\n",
            "        loss_decode=dict(\n",
            "            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=0.4)),\n",
            "    train_cfg=dict(),\n",
            "    test_cfg=dict(mode='whole'))\n",
            "dataset_type = 'CKDataset'\n",
            "data_root = '/content/drive/MyDrive/mmsegmentation/data'\n",
            "img_norm_cfg = dict(\n",
            "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
            "crop_size = (256, 256)\n",
            "train_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(type='LoadAnnotations'),\n",
            "    dict(type='Resize', img_scale=(640, 360), keep_ratio=True),\n",
            "    dict(type='RandomCrop', crop_size=(256, 256), cat_max_ratio=0.75),\n",
            "    dict(type='RandomFlip', prob=0.5),\n",
            "    dict(type='PhotoMetricDistortion'),\n",
            "    dict(\n",
            "        type='Normalize',\n",
            "        mean=[123.675, 116.28, 103.53],\n",
            "        std=[58.395, 57.12, 57.375],\n",
            "        to_rgb=True),\n",
            "    dict(type='Pad', size=(256, 256), pad_val=0, seg_pad_val=255),\n",
            "    dict(type='DefaultFormatBundle'),\n",
            "    dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n",
            "]\n",
            "test_pipeline = [\n",
            "    dict(type='LoadImageFromFile'),\n",
            "    dict(\n",
            "        type='MultiScaleFlipAug',\n",
            "        img_scale=(640, 360),\n",
            "        flip=False,\n",
            "        transforms=[\n",
            "            dict(type='Resize', keep_ratio=True),\n",
            "            dict(type='RandomFlip'),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_rgb=True),\n",
            "            dict(type='ImageToTensor', keys=['img']),\n",
            "            dict(type='Collect', keys=['img'])\n",
            "        ])\n",
            "]\n",
            "data = dict(\n",
            "    samples_per_gpu=2,\n",
            "    workers_per_gpu=2,\n",
            "    train=dict(\n",
            "        type='CKDataset',\n",
            "        data_root='/content/drive/MyDrive/mmsegmentation/data',\n",
            "        img_dir='images',\n",
            "        ann_dir='labels',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(type='LoadAnnotations'),\n",
            "            dict(type='Resize', img_scale=(640, 360), keep_ratio=True),\n",
            "            dict(type='RandomCrop', crop_size=(256, 256), cat_max_ratio=0.75),\n",
            "            dict(type='RandomFlip', prob=0.5),\n",
            "            dict(type='PhotoMetricDistortion'),\n",
            "            dict(\n",
            "                type='Normalize',\n",
            "                mean=[123.675, 116.28, 103.53],\n",
            "                std=[58.395, 57.12, 57.375],\n",
            "                to_rgb=True),\n",
            "            dict(type='Pad', size=(256, 256), pad_val=0, seg_pad_val=255),\n",
            "            dict(type='DefaultFormatBundle'),\n",
            "            dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n",
            "        ],\n",
            "        split='splits/train.txt'),\n",
            "    val=dict(\n",
            "        type='CKDataset',\n",
            "        data_root='/content/drive/MyDrive/mmsegmentation/data',\n",
            "        img_dir='images',\n",
            "        ann_dir='labels',\n",
            "        split='splits/val.txt',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=(640, 360),\n",
            "                flip=False,\n",
            "                transforms=[\n",
            "                    dict(type='Resize', keep_ratio=True),\n",
            "                    dict(type='RandomFlip'),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[123.675, 116.28, 103.53],\n",
            "                        std=[58.395, 57.12, 57.375],\n",
            "                        to_rgb=True),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ]),\n",
            "    test=dict(\n",
            "        type='CKDataset',\n",
            "        data_root='/content/drive/MyDrive/mmsegmentation/data',\n",
            "        img_dir='images',\n",
            "        ann_dir='labels',\n",
            "        split='splits/test.txt',\n",
            "        pipeline=[\n",
            "            dict(type='LoadImageFromFile'),\n",
            "            dict(\n",
            "                type='MultiScaleFlipAug',\n",
            "                img_scale=(640, 360),\n",
            "                flip=False,\n",
            "                transforms=[\n",
            "                    dict(type='Resize', keep_ratio=True),\n",
            "                    dict(type='RandomFlip'),\n",
            "                    dict(\n",
            "                        type='Normalize',\n",
            "                        mean=[123.675, 116.28, 103.53],\n",
            "                        std=[58.395, 57.12, 57.375],\n",
            "                        to_rgb=True),\n",
            "                    dict(type='ImageToTensor', keys=['img']),\n",
            "                    dict(type='Collect', keys=['img'])\n",
            "                ])\n",
            "        ]))\n",
            "log_config = dict(\n",
            "    interval=50, hooks=[dict(type='TextLoggerHook', by_epoch=False)])\n",
            "dist_params = dict(backend='nccl')\n",
            "log_level = 'INFO'\n",
            "load_from = None\n",
            "resume_from = None\n",
            "workflow = [('train', 1)]\n",
            "cudnn_benchmark = True\n",
            "optimizer = dict(\n",
            "    type='AdamW',\n",
            "    lr=6e-05,\n",
            "    betas=(0.9, 0.999),\n",
            "    weight_decay=0.01,\n",
            "    paramwise_cfg=dict(\n",
            "        custom_keys=dict(\n",
            "            absolute_pos_embed=dict(decay_mult=0.0),\n",
            "            relative_position_bias_table=dict(decay_mult=0.0),\n",
            "            norm=dict(decay_mult=0.0))))\n",
            "optimizer_config = dict()\n",
            "lr_config = dict(\n",
            "    policy='poly',\n",
            "    warmup='linear',\n",
            "    warmup_iters=1500,\n",
            "    warmup_ratio=1e-06,\n",
            "    power=1.0,\n",
            "    min_lr=0.0,\n",
            "    by_epoch=False)\n",
            "runner = dict(type='IterBasedRunner', max_iters=40000)\n",
            "checkpoint_config = dict(by_epoch=False, interval=4000)\n",
            "evaluation = dict(interval=4000, metric='mIoU', pre_eval=True)\n",
            "checkpoint_file = '/content/drive/MyDrive/mmsegmentation/checkpoints/upernet_swin_tiny_patch4_window7_512x512_160k_ade20k_pretrain_224x224_1K_20210531_112542-e380ad3e.pth'\n",
            "work_dir = './work_dirs/upernet_swin_tiny_patch4_window7_256*256_40k_ade20k_pretrain_224*224_1Kcrack'\n",
            "gpu_ids = [0]\n",
            "auto_resume = False\n",
            "\n",
            "2022-05-16 08:42:14,092 - mmseg - INFO - Set random seed to 1998907101, deterministic: False\n",
            "/content/drive/MyDrive/mmsegmentation/mmseg/models/losses/cross_entropy_loss.py:236: UserWarning: Default ``avg_non_ignore`` is False, if you would like to ignore the certain label and average loss over non-ignore labels, which is the same with PyTorch official cross_entropy, set ``avg_non_ignore=True``.\n",
            "  'Default ``avg_non_ignore`` is False, if you would like to '\n",
            "2022-05-16 08:42:15,088 - mmseg - INFO - load checkpoint from local path: /content/drive/MyDrive/mmsegmentation/checkpoints/upernet_swin_tiny_patch4_window7_512x512_160k_ade20k_pretrain_224x224_1K_20210531_112542-e380ad3e.pth\n",
            "2022-05-16 08:42:15,641 - mmseg - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "unexpected key in source state_dict: decode_head.conv_seg.weight, decode_head.conv_seg.bias, decode_head.psp_modules.0.1.conv.weight, decode_head.psp_modules.0.1.bn.weight, decode_head.psp_modules.0.1.bn.bias, decode_head.psp_modules.0.1.bn.running_mean, decode_head.psp_modules.0.1.bn.running_var, decode_head.psp_modules.0.1.bn.num_batches_tracked, decode_head.psp_modules.1.1.conv.weight, decode_head.psp_modules.1.1.bn.weight, decode_head.psp_modules.1.1.bn.bias, decode_head.psp_modules.1.1.bn.running_mean, decode_head.psp_modules.1.1.bn.running_var, decode_head.psp_modules.1.1.bn.num_batches_tracked, decode_head.psp_modules.2.1.conv.weight, decode_head.psp_modules.2.1.bn.weight, decode_head.psp_modules.2.1.bn.bias, decode_head.psp_modules.2.1.bn.running_mean, decode_head.psp_modules.2.1.bn.running_var, decode_head.psp_modules.2.1.bn.num_batches_tracked, decode_head.psp_modules.3.1.conv.weight, decode_head.psp_modules.3.1.bn.weight, decode_head.psp_modules.3.1.bn.bias, decode_head.psp_modules.3.1.bn.running_mean, decode_head.psp_modules.3.1.bn.running_var, decode_head.psp_modules.3.1.bn.num_batches_tracked, decode_head.bottleneck.conv.weight, decode_head.bottleneck.bn.weight, decode_head.bottleneck.bn.bias, decode_head.bottleneck.bn.running_mean, decode_head.bottleneck.bn.running_var, decode_head.bottleneck.bn.num_batches_tracked, decode_head.lateral_convs.0.conv.weight, decode_head.lateral_convs.0.bn.weight, decode_head.lateral_convs.0.bn.bias, decode_head.lateral_convs.0.bn.running_mean, decode_head.lateral_convs.0.bn.running_var, decode_head.lateral_convs.0.bn.num_batches_tracked, decode_head.lateral_convs.1.conv.weight, decode_head.lateral_convs.1.bn.weight, decode_head.lateral_convs.1.bn.bias, decode_head.lateral_convs.1.bn.running_mean, decode_head.lateral_convs.1.bn.running_var, decode_head.lateral_convs.1.bn.num_batches_tracked, decode_head.lateral_convs.2.conv.weight, decode_head.lateral_convs.2.bn.weight, decode_head.lateral_convs.2.bn.bias, decode_head.lateral_convs.2.bn.running_mean, decode_head.lateral_convs.2.bn.running_var, decode_head.lateral_convs.2.bn.num_batches_tracked, decode_head.fpn_convs.0.conv.weight, decode_head.fpn_convs.0.bn.weight, decode_head.fpn_convs.0.bn.bias, decode_head.fpn_convs.0.bn.running_mean, decode_head.fpn_convs.0.bn.running_var, decode_head.fpn_convs.0.bn.num_batches_tracked, decode_head.fpn_convs.1.conv.weight, decode_head.fpn_convs.1.bn.weight, decode_head.fpn_convs.1.bn.bias, decode_head.fpn_convs.1.bn.running_mean, decode_head.fpn_convs.1.bn.running_var, decode_head.fpn_convs.1.bn.num_batches_tracked, decode_head.fpn_convs.2.conv.weight, decode_head.fpn_convs.2.bn.weight, decode_head.fpn_convs.2.bn.bias, decode_head.fpn_convs.2.bn.running_mean, decode_head.fpn_convs.2.bn.running_var, decode_head.fpn_convs.2.bn.num_batches_tracked, decode_head.fpn_bottleneck.conv.weight, decode_head.fpn_bottleneck.bn.weight, decode_head.fpn_bottleneck.bn.bias, decode_head.fpn_bottleneck.bn.running_mean, decode_head.fpn_bottleneck.bn.running_var, decode_head.fpn_bottleneck.bn.num_batches_tracked, auxiliary_head.conv_seg.weight, auxiliary_head.conv_seg.bias, auxiliary_head.convs.0.conv.weight, auxiliary_head.convs.0.bn.weight, auxiliary_head.convs.0.bn.bias, auxiliary_head.convs.0.bn.running_mean, auxiliary_head.convs.0.bn.running_var, auxiliary_head.convs.0.bn.num_batches_tracked\n",
            "\n",
            "2022-05-16 08:42:15,674 - mmseg - INFO - initialize UPerHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n",
            "2022-05-16 08:42:15,980 - mmseg - INFO - initialize FCNHead with init_cfg {'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n",
            "tools/train.py:205: UserWarning: SyncBN is only supported with DDP. To be compatible with DP, we convert SyncBN to BN. Please use dist_train.sh which can avoid this error.\n",
            "  'SyncBN is only supported with DDP. To be compatible with DP, '\n",
            "2022-05-16 08:42:15,991 - mmseg - INFO - EncoderDecoder(\n",
            "  (backbone): SwinTransformer(\n",
            "    (patch_embed): PatchEmbed(\n",
            "      (adap_padding): AdaptivePadding()\n",
            "      (projection): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
            "      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (drop_after_pos): Dropout(p=0.0, inplace=False)\n",
            "    (stages): ModuleList(\n",
            "      (0): SwinBlockSequence(\n",
            "        (blocks): ModuleList(\n",
            "          (0): SwinBlock(\n",
            "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ShiftWindowMSA(\n",
            "              (w_msa): WindowMSA(\n",
            "                (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
            "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "                (proj): Linear(in_features=96, out_features=96, bias=True)\n",
            "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "                (softmax): Softmax(dim=-1)\n",
            "              )\n",
            "              (drop): DropPath()\n",
            "            )\n",
            "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "            (ffn): FFN(\n",
            "              (activate): GELU()\n",
            "              (layers): Sequential(\n",
            "                (0): Sequential(\n",
            "                  (0): Linear(in_features=96, out_features=384, bias=True)\n",
            "                  (1): GELU()\n",
            "                  (2): Dropout(p=0.0, inplace=False)\n",
            "                )\n",
            "                (1): Linear(in_features=384, out_features=96, bias=True)\n",
            "                (2): Dropout(p=0.0, inplace=False)\n",
            "              )\n",
            "              (dropout_layer): DropPath()\n",
            "            )\n",
            "          )\n",
            "          (1): SwinBlock(\n",
            "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ShiftWindowMSA(\n",
            "              (w_msa): WindowMSA(\n",
            "                (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
            "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "                (proj): Linear(in_features=96, out_features=96, bias=True)\n",
            "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "                (softmax): Softmax(dim=-1)\n",
            "              )\n",
            "              (drop): DropPath()\n",
            "            )\n",
            "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "            (ffn): FFN(\n",
            "              (activate): GELU()\n",
            "              (layers): Sequential(\n",
            "                (0): Sequential(\n",
            "                  (0): Linear(in_features=96, out_features=384, bias=True)\n",
            "                  (1): GELU()\n",
            "                  (2): Dropout(p=0.0, inplace=False)\n",
            "                )\n",
            "                (1): Linear(in_features=384, out_features=96, bias=True)\n",
            "                (2): Dropout(p=0.0, inplace=False)\n",
            "              )\n",
            "              (dropout_layer): DropPath()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (downsample): PatchMerging(\n",
            "          (adap_padding): AdaptivePadding()\n",
            "          (sampler): Unfold(kernel_size=(2, 2), dilation=(1, 1), padding=(0, 0), stride=(2, 2))\n",
            "          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "          (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
            "        )\n",
            "      )\n",
            "      (1): SwinBlockSequence(\n",
            "        (blocks): ModuleList(\n",
            "          (0): SwinBlock(\n",
            "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ShiftWindowMSA(\n",
            "              (w_msa): WindowMSA(\n",
            "                (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
            "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "                (proj): Linear(in_features=192, out_features=192, bias=True)\n",
            "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "                (softmax): Softmax(dim=-1)\n",
            "              )\n",
            "              (drop): DropPath()\n",
            "            )\n",
            "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "            (ffn): FFN(\n",
            "              (activate): GELU()\n",
            "              (layers): Sequential(\n",
            "                (0): Sequential(\n",
            "                  (0): Linear(in_features=192, out_features=768, bias=True)\n",
            "                  (1): GELU()\n",
            "                  (2): Dropout(p=0.0, inplace=False)\n",
            "                )\n",
            "                (1): Linear(in_features=768, out_features=192, bias=True)\n",
            "                (2): Dropout(p=0.0, inplace=False)\n",
            "              )\n",
            "              (dropout_layer): DropPath()\n",
            "            )\n",
            "          )\n",
            "          (1): SwinBlock(\n",
            "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ShiftWindowMSA(\n",
            "              (w_msa): WindowMSA(\n",
            "                (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
            "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "                (proj): Linear(in_features=192, out_features=192, bias=True)\n",
            "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "                (softmax): Softmax(dim=-1)\n",
            "              )\n",
            "              (drop): DropPath()\n",
            "            )\n",
            "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "            (ffn): FFN(\n",
            "              (activate): GELU()\n",
            "              (layers): Sequential(\n",
            "                (0): Sequential(\n",
            "                  (0): Linear(in_features=192, out_features=768, bias=True)\n",
            "                  (1): GELU()\n",
            "                  (2): Dropout(p=0.0, inplace=False)\n",
            "                )\n",
            "                (1): Linear(in_features=768, out_features=192, bias=True)\n",
            "                (2): Dropout(p=0.0, inplace=False)\n",
            "              )\n",
            "              (dropout_layer): DropPath()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (downsample): PatchMerging(\n",
            "          (adap_padding): AdaptivePadding()\n",
            "          (sampler): Unfold(kernel_size=(2, 2), dilation=(1, 1), padding=(0, 0), stride=(2, 2))\n",
            "          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
            "        )\n",
            "      )\n",
            "      (2): SwinBlockSequence(\n",
            "        (blocks): ModuleList(\n",
            "          (0): SwinBlock(\n",
            "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ShiftWindowMSA(\n",
            "              (w_msa): WindowMSA(\n",
            "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
            "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "                (softmax): Softmax(dim=-1)\n",
            "              )\n",
            "              (drop): DropPath()\n",
            "            )\n",
            "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "            (ffn): FFN(\n",
            "              (activate): GELU()\n",
            "              (layers): Sequential(\n",
            "                (0): Sequential(\n",
            "                  (0): Linear(in_features=384, out_features=1536, bias=True)\n",
            "                  (1): GELU()\n",
            "                  (2): Dropout(p=0.0, inplace=False)\n",
            "                )\n",
            "                (1): Linear(in_features=1536, out_features=384, bias=True)\n",
            "                (2): Dropout(p=0.0, inplace=False)\n",
            "              )\n",
            "              (dropout_layer): DropPath()\n",
            "            )\n",
            "          )\n",
            "          (1): SwinBlock(\n",
            "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ShiftWindowMSA(\n",
            "              (w_msa): WindowMSA(\n",
            "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
            "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "                (softmax): Softmax(dim=-1)\n",
            "              )\n",
            "              (drop): DropPath()\n",
            "            )\n",
            "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "            (ffn): FFN(\n",
            "              (activate): GELU()\n",
            "              (layers): Sequential(\n",
            "                (0): Sequential(\n",
            "                  (0): Linear(in_features=384, out_features=1536, bias=True)\n",
            "                  (1): GELU()\n",
            "                  (2): Dropout(p=0.0, inplace=False)\n",
            "                )\n",
            "                (1): Linear(in_features=1536, out_features=384, bias=True)\n",
            "                (2): Dropout(p=0.0, inplace=False)\n",
            "              )\n",
            "              (dropout_layer): DropPath()\n",
            "            )\n",
            "          )\n",
            "          (2): SwinBlock(\n",
            "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ShiftWindowMSA(\n",
            "              (w_msa): WindowMSA(\n",
            "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
            "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "                (softmax): Softmax(dim=-1)\n",
            "              )\n",
            "              (drop): DropPath()\n",
            "            )\n",
            "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "            (ffn): FFN(\n",
            "              (activate): GELU()\n",
            "              (layers): Sequential(\n",
            "                (0): Sequential(\n",
            "                  (0): Linear(in_features=384, out_features=1536, bias=True)\n",
            "                  (1): GELU()\n",
            "                  (2): Dropout(p=0.0, inplace=False)\n",
            "                )\n",
            "                (1): Linear(in_features=1536, out_features=384, bias=True)\n",
            "                (2): Dropout(p=0.0, inplace=False)\n",
            "              )\n",
            "              (dropout_layer): DropPath()\n",
            "            )\n",
            "          )\n",
            "          (3): SwinBlock(\n",
            "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ShiftWindowMSA(\n",
            "              (w_msa): WindowMSA(\n",
            "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
            "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "                (softmax): Softmax(dim=-1)\n",
            "              )\n",
            "              (drop): DropPath()\n",
            "            )\n",
            "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "            (ffn): FFN(\n",
            "              (activate): GELU()\n",
            "              (layers): Sequential(\n",
            "                (0): Sequential(\n",
            "                  (0): Linear(in_features=384, out_features=1536, bias=True)\n",
            "                  (1): GELU()\n",
            "                  (2): Dropout(p=0.0, inplace=False)\n",
            "                )\n",
            "                (1): Linear(in_features=1536, out_features=384, bias=True)\n",
            "                (2): Dropout(p=0.0, inplace=False)\n",
            "              )\n",
            "              (dropout_layer): DropPath()\n",
            "            )\n",
            "          )\n",
            "          (4): SwinBlock(\n",
            "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ShiftWindowMSA(\n",
            "              (w_msa): WindowMSA(\n",
            "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
            "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "                (softmax): Softmax(dim=-1)\n",
            "              )\n",
            "              (drop): DropPath()\n",
            "            )\n",
            "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "            (ffn): FFN(\n",
            "              (activate): GELU()\n",
            "              (layers): Sequential(\n",
            "                (0): Sequential(\n",
            "                  (0): Linear(in_features=384, out_features=1536, bias=True)\n",
            "                  (1): GELU()\n",
            "                  (2): Dropout(p=0.0, inplace=False)\n",
            "                )\n",
            "                (1): Linear(in_features=1536, out_features=384, bias=True)\n",
            "                (2): Dropout(p=0.0, inplace=False)\n",
            "              )\n",
            "              (dropout_layer): DropPath()\n",
            "            )\n",
            "          )\n",
            "          (5): SwinBlock(\n",
            "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ShiftWindowMSA(\n",
            "              (w_msa): WindowMSA(\n",
            "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
            "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "                (softmax): Softmax(dim=-1)\n",
            "              )\n",
            "              (drop): DropPath()\n",
            "            )\n",
            "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "            (ffn): FFN(\n",
            "              (activate): GELU()\n",
            "              (layers): Sequential(\n",
            "                (0): Sequential(\n",
            "                  (0): Linear(in_features=384, out_features=1536, bias=True)\n",
            "                  (1): GELU()\n",
            "                  (2): Dropout(p=0.0, inplace=False)\n",
            "                )\n",
            "                (1): Linear(in_features=1536, out_features=384, bias=True)\n",
            "                (2): Dropout(p=0.0, inplace=False)\n",
            "              )\n",
            "              (dropout_layer): DropPath()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (downsample): PatchMerging(\n",
            "          (adap_padding): AdaptivePadding()\n",
            "          (sampler): Unfold(kernel_size=(2, 2), dilation=(1, 1), padding=(0, 0), stride=(2, 2))\n",
            "          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
            "          (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
            "        )\n",
            "      )\n",
            "      (3): SwinBlockSequence(\n",
            "        (blocks): ModuleList(\n",
            "          (0): SwinBlock(\n",
            "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ShiftWindowMSA(\n",
            "              (w_msa): WindowMSA(\n",
            "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "                (softmax): Softmax(dim=-1)\n",
            "              )\n",
            "              (drop): DropPath()\n",
            "            )\n",
            "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (ffn): FFN(\n",
            "              (activate): GELU()\n",
            "              (layers): Sequential(\n",
            "                (0): Sequential(\n",
            "                  (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                  (1): GELU()\n",
            "                  (2): Dropout(p=0.0, inplace=False)\n",
            "                )\n",
            "                (1): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (2): Dropout(p=0.0, inplace=False)\n",
            "              )\n",
            "              (dropout_layer): DropPath()\n",
            "            )\n",
            "          )\n",
            "          (1): SwinBlock(\n",
            "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): ShiftWindowMSA(\n",
            "              (w_msa): WindowMSA(\n",
            "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "                (softmax): Softmax(dim=-1)\n",
            "              )\n",
            "              (drop): DropPath()\n",
            "            )\n",
            "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (ffn): FFN(\n",
            "              (activate): GELU()\n",
            "              (layers): Sequential(\n",
            "                (0): Sequential(\n",
            "                  (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                  (1): GELU()\n",
            "                  (2): Dropout(p=0.0, inplace=False)\n",
            "                )\n",
            "                (1): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (2): Dropout(p=0.0, inplace=False)\n",
            "              )\n",
            "              (dropout_layer): DropPath()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (norm0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "    (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
            "    (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "    (norm3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  init_cfg={'type': 'Pretrained', 'checkpoint': '/content/drive/MyDrive/mmsegmentation/checkpoints/upernet_swin_tiny_patch4_window7_512x512_160k_ade20k_pretrain_224x224_1K_20210531_112542-e380ad3e.pth'}\n",
            "  (decode_head): UPerHead(\n",
            "    input_transform=multiple_select, ignore_index=255, align_corners=False\n",
            "    (loss_decode): CrossEntropyLoss(avg_non_ignore=False)\n",
            "    (conv_seg): Conv2d(512, 150, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
            "    (psp_modules): PPM(\n",
            "      (0): Sequential(\n",
            "        (0): AdaptiveAvgPool2d(output_size=1)\n",
            "        (1): ConvModule(\n",
            "          (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activate): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): AdaptiveAvgPool2d(output_size=2)\n",
            "        (1): ConvModule(\n",
            "          (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activate): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): AdaptiveAvgPool2d(output_size=3)\n",
            "        (1): ConvModule(\n",
            "          (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activate): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (3): Sequential(\n",
            "        (0): AdaptiveAvgPool2d(output_size=6)\n",
            "        (1): ConvModule(\n",
            "          (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activate): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (bottleneck): ConvModule(\n",
            "      (conv): Conv2d(2816, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (activate): ReLU(inplace=True)\n",
            "    )\n",
            "    (lateral_convs): ModuleList(\n",
            "      (0): ConvModule(\n",
            "        (conv): Conv2d(96, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activate): ReLU()\n",
            "      )\n",
            "      (1): ConvModule(\n",
            "        (conv): Conv2d(192, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activate): ReLU()\n",
            "      )\n",
            "      (2): ConvModule(\n",
            "        (conv): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activate): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (fpn_convs): ModuleList(\n",
            "      (0): ConvModule(\n",
            "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activate): ReLU()\n",
            "      )\n",
            "      (1): ConvModule(\n",
            "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activate): ReLU()\n",
            "      )\n",
            "      (2): ConvModule(\n",
            "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activate): ReLU()\n",
            "      )\n",
            "    )\n",
            "    (fpn_bottleneck): ConvModule(\n",
            "      (conv): Conv2d(2048, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): _BatchNormXd(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (activate): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n",
            "  (auxiliary_head): FCNHead(\n",
            "    input_transform=None, ignore_index=255, align_corners=False\n",
            "    (loss_decode): CrossEntropyLoss(avg_non_ignore=False)\n",
            "    (conv_seg): Conv2d(256, 150, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
            "    (convs): Sequential(\n",
            "      (0): ConvModule(\n",
            "        (conv): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn): _BatchNormXd(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activate): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  init_cfg={'type': 'Normal', 'std': 0.01, 'override': {'name': 'conv_seg'}}\n",
            ")\n",
            "2022-05-16 08:42:16,107 - mmseg - INFO - Loaded 2017 images\n",
            "2022-05-16 08:42:22,505 - mmseg - INFO - Loaded 673 images\n",
            "2022-05-16 08:42:22,507 - mmseg - INFO - Start running, host: root@02982fa04db4, work_dir: /content/drive/MyDrive/mmsegmentation/work_dirs/upernet_swin_tiny_patch4_window7_256*256_40k_ade20k_pretrain_224*224_1Kcrack\n",
            "2022-05-16 08:42:22,508 - mmseg - INFO - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) PolyLrUpdaterHook                  \n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(LOW         ) EvalHook                           \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) PolyLrUpdaterHook                  \n",
            "(LOW         ) IterTimerHook                      \n",
            "(LOW         ) EvalHook                           \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) PolyLrUpdaterHook                  \n",
            "(LOW         ) IterTimerHook                      \n",
            "(LOW         ) EvalHook                           \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(ABOVE_NORMAL) OptimizerHook                      \n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(LOW         ) IterTimerHook                      \n",
            "(LOW         ) EvalHook                           \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(LOW         ) EvalHook                           \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(LOW         ) IterTimerHook                      \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(LOW         ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(LOW         ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "after_run:\n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            " -------------------- \n",
            "2022-05-16 08:42:22,508 - mmseg - INFO - workflow: [('train', 1)], max: 40000 iters\n",
            "2022-05-16 08:42:22,509 - mmseg - INFO - Checkpoints will be saved to /content/drive/MyDrive/mmsegmentation/work_dirs/upernet_swin_tiny_patch4_window7_256*256_40k_ade20k_pretrain_224*224_1Kcrack by HardDiskBackend.\n",
            "2022-05-16 08:43:09,466 - mmseg - INFO - Iter [50/40000]\tlr: 1.958e-06, eta: 10:23:45, time: 0.937, data_time: 0.007, memory: 9292, decode.loss_ce: 5.0828, decode.acc_seg: 0.2807, aux.loss_ce: 1.9902, aux.acc_seg: 1.6014, loss: 7.0730\n",
            "2022-05-16 08:43:42,875 - mmseg - INFO - Iter [100/40000]\tlr: 3.950e-06, eta: 8:53:39, time: 0.668, data_time: 0.003, memory: 9292, decode.loss_ce: 5.0299, decode.acc_seg: 1.0648, aux.loss_ce: 1.9853, aux.acc_seg: 1.6219, loss: 7.0152\n",
            "2022-05-16 08:44:16,179 - mmseg - INFO - Iter [150/40000]\tlr: 5.938e-06, eta: 8:22:47, time: 0.666, data_time: 0.003, memory: 9292, decode.loss_ce: 4.9298, decode.acc_seg: 5.7114, aux.loss_ce: 1.9676, aux.acc_seg: 4.9160, loss: 6.8975\n",
            "2022-05-16 08:44:49,416 - mmseg - INFO - Iter [200/40000]\tlr: 7.920e-06, eta: 8:06:51, time: 0.665, data_time: 0.003, memory: 9292, decode.loss_ce: 4.8071, decode.acc_seg: 17.4953, aux.loss_ce: 1.9412, aux.acc_seg: 16.1138, loss: 6.7482\n",
            "2022-05-16 08:45:22,399 - mmseg - INFO - Iter [250/40000]\tlr: 9.898e-06, eta: 7:56:23, time: 0.660, data_time: 0.003, memory: 9292, decode.loss_ce: 4.6140, decode.acc_seg: 45.9758, aux.loss_ce: 1.9107, aux.acc_seg: 38.1334, loss: 6.5247\n",
            "2022-05-16 08:45:55,084 - mmseg - INFO - Iter [300/40000]\tlr: 1.187e-05, eta: 7:48:35, time: 0.654, data_time: 0.003, memory: 9292, decode.loss_ce: 4.3012, decode.acc_seg: 67.2289, aux.loss_ce: 1.8667, aux.acc_seg: 70.6230, loss: 6.1679\n",
            "2022-05-16 08:46:27,442 - mmseg - INFO - Iter [350/40000]\tlr: 1.384e-05, eta: 7:42:13, time: 0.647, data_time: 0.003, memory: 9292, decode.loss_ce: 3.9912, decode.acc_seg: 73.2479, aux.loss_ce: 1.8138, aux.acc_seg: 81.4048, loss: 5.8051\n",
            "2022-05-16 08:46:59,461 - mmseg - INFO - Iter [400/40000]\tlr: 1.580e-05, eta: 7:36:46, time: 0.640, data_time: 0.003, memory: 9292, decode.loss_ce: 3.7414, decode.acc_seg: 75.0120, aux.loss_ce: 1.7527, aux.acc_seg: 80.8780, loss: 5.4941\n",
            "2022-05-16 08:47:31,309 - mmseg - INFO - Iter [450/40000]\tlr: 1.776e-05, eta: 7:32:09, time: 0.637, data_time: 0.003, memory: 9292, decode.loss_ce: 3.4607, decode.acc_seg: 77.4697, aux.loss_ce: 1.6799, aux.acc_seg: 78.8906, loss: 5.1406\n",
            "2022-05-16 08:48:03,172 - mmseg - INFO - Iter [500/40000]\tlr: 1.971e-05, eta: 7:28:22, time: 0.637, data_time: 0.003, memory: 9292, decode.loss_ce: 3.1449, decode.acc_seg: 79.5359, aux.loss_ce: 1.6034, aux.acc_seg: 77.7996, loss: 4.7483\n",
            "2022-05-16 08:48:35,066 - mmseg - INFO - Iter [550/40000]\tlr: 2.166e-05, eta: 7:25:13, time: 0.638, data_time: 0.003, memory: 9292, decode.loss_ce: 2.7814, decode.acc_seg: 82.3165, aux.loss_ce: 1.5135, aux.acc_seg: 77.7700, loss: 4.2949\n",
            "2022-05-16 08:49:06,900 - mmseg - INFO - Iter [600/40000]\tlr: 2.360e-05, eta: 7:22:26, time: 0.637, data_time: 0.003, memory: 9292, decode.loss_ce: 2.3924, decode.acc_seg: 86.5499, aux.loss_ce: 1.4335, aux.acc_seg: 79.6654, loss: 3.8259\n",
            "2022-05-16 08:49:38,743 - mmseg - INFO - Iter [650/40000]\tlr: 2.554e-05, eta: 7:20:01, time: 0.637, data_time: 0.003, memory: 9292, decode.loss_ce: 2.0151, decode.acc_seg: 89.7529, aux.loss_ce: 1.3450, aux.acc_seg: 76.5339, loss: 3.3601\n",
            "2022-05-16 08:50:10,423 - mmseg - INFO - Iter [700/40000]\tlr: 2.747e-05, eta: 7:17:43, time: 0.634, data_time: 0.003, memory: 9292, decode.loss_ce: 1.5494, decode.acc_seg: 92.8504, aux.loss_ce: 1.2317, aux.acc_seg: 82.0260, loss: 2.7811\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#设置对像并训练"
      ],
      "metadata": {
        "id": "3Ndz4TW5wP5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#导入模型设置模块并赋值给cfg（把一个Configs文件中的模型设置文件作为修改基础）\n",
        "from mmcv import Config\n",
        "cfg = Config.fromfile('configs/swin/upernet_swin_tiny_patch4_window7_256*256_40k_ade20k_pretrain_224*224_1Kcrack.py')"
      ],
      "metadata": {
        "id": "MnjKgd2HpS3N"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mmseg.apis import set_random_seed"
      ],
      "metadata": {
        "id": "pSR37CqypS0h"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#使用单个gpu所以要用BN,并需要把模型中的骨架、解码头和辅助头中的设置都进行赋值修改\n",
        "cfg.norm_cfg = dict(type='BN', requires_grad=True)\n",
        "cfg.model.backbone.norm_cfg = cfg.norm_cfg\n",
        "cfg.model.decode_head.norm_cfg = cfg.norm_cfg\n",
        "cfg.model.auxiliary_head.norm_cfg = cfg.norm_cfg"
      ],
      "metadata": {
        "id": "q1mV3OkdpSx6"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#修改解码头和辅助头中的类别数量\n",
        "cfg.model.decode_head.num_classes = 19\n",
        "cfg.model.auxiliary_head.num_classes = 19"
      ],
      "metadata": {
        "id": "bkQSPqqWpSvO"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#修改每个gpu的样本量和每个gpu的工作流数（按照gpu的核数来修改）\n",
        "cfg.data.samples_per_gpu = 8   #数据集上的bachsize数，8比较常用\n",
        "cfg.data.workers_per_gpu = 2   #数据集上的进程数，colab上是双核gpu"
      ],
      "metadata": {
        "id": "tABM-_D9pSr8"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#修改剪裁尺寸\n",
        "cfg.crop_size = (256, 256)"
      ],
      "metadata": {
        "id": "aJ1x66JRpSnZ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#设置随机种子以复现训练结果，设置gpu数为1个\n",
        "cfg.seed = 0\n",
        "set_random_seed(0, deterministic=False)\n",
        "cfg.gpu_ids = range(1)"
      ],
      "metadata": {
        "id": "RNW0ZWybpSks"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#设置模型和日志储藏路径\n",
        "cfg.work_dir = '../drive/MyDrive/Swin-Transformer-Semantic-Segmentation/work_dirs/upernet_swin_tiny_patch4_window7_512*512_40k_ade20k_pretrain_224*224_1Kcrack'"
      ],
      "metadata": {
        "id": "eyrvZJwkpSgd"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import copy\n",
        "import os\n",
        "import os.path as osp\n",
        "import time\n",
        "import warnings\n",
        "\n",
        "import mmcv\n",
        "import torch\n",
        "import torch.distributed as dist\n",
        "from mmcv.cnn.utils import revert_sync_batchnorm\n",
        "from mmcv.runner import get_dist_info, init_dist\n",
        "from mmcv.utils import Config, DictAction, get_git_hash\n",
        "\n",
        "from mmseg import __version__\n",
        "from mmseg.apis import init_random_seed, set_random_seed, train_segmentor\n",
        "from mmseg.datasets import build_dataset\n",
        "from mmseg.models import build_segmentor\n",
        "from mmseg.utils import collect_env, get_root_logger, setup_multi_processes\n",
        "from mmseg.datasets.crack import CKDataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "dCoeceSepSZp",
        "outputId": "117f7d08-e6e4-425f-b8e3-5c6f5ef80e7c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-9291f8151c3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmmseg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_segmentor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmmseg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcollect_env\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_root_logger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msetup_multi_processes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmmseg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrack\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCKDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mmseg.datasets.crack'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mmseg.datasets import build_dataset\n",
        "from mmseg.models import build_segmentor\n",
        "from mmseg.apis import train_segmentor"
      ],
      "metadata": {
        "id": "HEr29RYypSP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path as osp\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "data_root = 'data'\n",
        "img_dir = 'images'\n",
        "ann_dir = 'labels'\n",
        "split_dir = 'splits'\n",
        "mmcv.mkdir_or_exist(osp.join(data_root, split_dir))\n",
        "filename_list = [osp.splitext(filename)[0] for filename in mmcv.scandir(osp.join(data_root, ann_dir), suffix= '.png')]\n",
        "with open(osp.join(data_root, split_dir, 'train.txt'), 'w') as f:\n",
        "    train_length = int(len(filename_list)*3/5)\n",
        "    val_length = int(len(filename_list)*4/5)\n",
        "    f.writelines(line + '\\n' for line in filename_list[:train_length])\n",
        "with open(osp.join(data_root, split_dir, 'val.txt'), 'w') as f:\n",
        "    f.writelines(line + '\\n' for line in filename_list[train_length:val_length])\n",
        "with open(osp.join(data_root, split_dir, 'test.txt'), 'w') as f:\n",
        "    f.writelines(line + '\\n' for line in filename_list[val_length:])  "
      ],
      "metadata": {
        "id": "qL0yEsFZzGvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#构建数据集\n",
        "datasets = [build_dataset(cfg.data.train)]"
      ],
      "metadata": {
        "id": "Aj2Dz9KWzGsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#构建模型\n",
        "model =build_segmentor(cfg.model)"
      ],
      "metadata": {
        "id": "AaoHKisOzGn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#将类别名增加到标签中以便于可视化\n",
        "model.CLASSES = datasets[0].CLASSES"
      ],
      "metadata": {
        "id": "NXjEy5G-zGls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#创建工作目录并训练\n",
        "import mmcv\n",
        "import os.path as osp\n",
        "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
        "train_segmentor(model, datasets, cfg, distributed=False, validate=True, meta=dict())"
      ],
      "metadata": {
        "id": "0bXmHDnezGin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iTXX2GJezGar"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "欢迎使用 Colaboratory",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}